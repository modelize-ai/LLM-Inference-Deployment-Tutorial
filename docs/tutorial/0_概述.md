<h1 align="center">概述</h1>

在本章节，我们会对整个教程进行一个概述，介绍后续各章节的核心内容，让读者对整个教程的知识脉络有一个比较清晰的把握，同时也方便读者有针对性的选择自己感兴趣或较陌生的话题来阅读，节省宝贵的时间。

## 话题范围

在当前版本，我们不会细致入微地涵盖大语言模型推理部署工程化落地的全方面内容。比如，我们不会讨论如何设计一个好的日志和监控告警系统，如何设计和实施分布式的容器化部署与管理，如何实现真正的负载均衡等等。在本教程，我们重点关注：大语言模型推理引擎设计与代码讲解，推理引擎的优化方向和实现思路，推理引擎的性能测试方法，以及硬件设备的选择。

> 对于本教程不会涉及的部分，若读者朋友们有强烈的学习意愿和需要，欢迎在 issue 中提出，我们将根据社区的反馈考虑是否增加相关章节。

## 各章节介绍

### 第一章 大语言模型推理引擎设计与代码讲解

在第一章中，我们首先对大语言模型推理引擎进行整体性介绍；然后，在余下小节里，我们将会更详细地对大语言模型推理引擎中的各模块进行讲解，并对相关代码进行说明，让读者最终能够自己动手实现一个简单的高性能推理引擎。

以下展示第一章所含的各小节：
0. 概述
1. 请求打包模块
2. 缓存管理模块
3. 模型执行模块
4. 模型工具模块
5. 生成工具模块
6. Server 封装和 HTTP 服务化

### 第二章 推理引擎的优化方向和实现思路

在第二章节中，我们结合现有流行的推理引擎和最新的研究进展来分析推理引擎在推理性能和生成质量等方面可进一步优化的方向，以及可能的实现思路。

以下展示第二章所含的各小节：
1. 模型和缓存压缩的优化
2. 生成策略的优化
3. 请求打包策略的优化
4. 其他可能的优化

### 第三章 推理引擎的性能测试方法

在第三章节中，我们将介绍如何有效地评估推理引擎的性能和根据实际业务流量的特征选择测试策略。

### 第四章 硬件设备的选择

在第四章节中，我们将介绍如何结合实际的业务场景来有针对性地选择 GPU。
